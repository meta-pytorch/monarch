name: Build CUDA

on:
  workflow_call:

concurrency:
  group: build-cuda-${{ github.workflow }}-${{ github.ref == 'refs/heads/main' && github.run_number || github.ref }}
  cancel-in-progress: true

jobs:
  build-cuda:
    name: Build CUDA (cuda12.6-py3.10)
    uses: pytorch/test-infra/.github/workflows/linux_job_v2.yml@main
    strategy:
      fail-fast: true
      matrix:
        include:
          - name: 4xlargegpu
            runs-on: linux.g5.4xlarge.nvidia.gpu
            torch-spec: '--pre torch --index-url https://download.pytorch.org/whl/nightly/cu126'
            gpu-arch-type: "cuda"
            gpu-arch-version: "12.6"
    with:
      timeout: 60
      runner: ${{ matrix.runs-on }}
      gpu-arch-type: ${{ matrix.gpu-arch-type }}
      gpu-arch-version: ${{ matrix.gpu-arch-version }}
      submodules: recursive
      upload-artifact: monarch-cuda-${{ github.sha }}
      script: |
        # Source common setup functions
        source scripts/common-setup.sh

        # Setup build environment (conda + system deps + rust + build deps)
        setup_build_environment

        # Setup Tensor Engine
        setup_tensor_engine

        # Build the process allocator binary
        build_process_allocator

        export CUDA_LIB_DIR=/usr/lib64

        # Build monarch (CUDA version)
        python setup.py bdist_wheel
