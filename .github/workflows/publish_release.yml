name: Build and publish versioned monarch wheels

on:
  workflow_dispatch:
    inputs:
      version:
        description: "Version string (e.g. 0.1.0rc1 or 0.1.0)"
        required: true

concurrency:
  group: ${{ github.workflow }}-${{ github.ref == 'refs/heads/main' && github.run_number || github.ref }}
  cancel-in-progress: true
jobs:
  build:
    name: ${{ matrix.name }}-py${{ matrix.python-version }}
    strategy:
      fail-fast: false
      matrix:
        # TODO add 3.14 once we figure out py03 issue
        python-version: ["3.10", "3.11", "3.12", "3.13"]
        include:
          # x86_64 CUDA builds
          - name: cuda12.8-x86_64
            runner: linux.g5.4xlarge.nvidia.gpu
            torch-spec: '--pre torch --index-url https://download.pytorch.org/whl/nightly/cu128'
            gpu-arch-type: "cuda"
            gpu-arch-version: "12.8"
            docker-image: "pytorch/almalinux-builder"  # Uses default, becomes pytorch/almalinux-builder:cuda12.8
            platform-tag: "manylinux2014_x86_64"
          # aarch64 CUDA builds
          - name: cuda12.8-aarch64
            runner: linux.arm64.r7g.12xlarge.memory  # GPU-enabled ARM runner like PyTorch uses
            torch-spec: '--pre torch --index-url https://download.pytorch.org/whl/nightly/cu128'
            gpu-arch-type: "cpu"  # Use "cpu" to skip nvidia driver install, CUDA libs are in Docker image
            gpu-arch-version: ""
            docker-image: "pytorch/manylinuxaarch64-builder:cuda12.8"  # ARM-specific image with CUDA
            platform-tag: "manylinux2014_aarch64"
    uses: pytorch/test-infra/.github/workflows/linux_job_v2.yml@main
    with:
      timeout: 60
      runner: ${{ matrix.runner }}
      gpu-arch-type: ${{ matrix.gpu-arch-type }}
      gpu-arch-version: ${{ matrix.gpu-arch-version }}
      docker-image: ${{ matrix.docker-image }}
      submodules: recursive
      upload-artifact: monarch-${{ matrix.python-version }}-${{ matrix.name }}
      script: |
        source scripts/common-setup.sh
        setup_build_environment ${{ matrix.python-version }}

        # Install torch nightly before installing the wheel,
        # so that we can test the wheel against the latest nightly
        pip install ${{ matrix.torch-spec }}
        pip install -r build-requirements.txt

        # Setup Tensor Engine dependencies
        setup_tensor_engine

        # Setup CUDA environment (detects CUDA paths automatically for both x86_64 and aarch64)
        setup_cuda_environment

        # Build wheel with proper library paths
        export MONARCH_PACKAGE_NAME="torchmonarch"
        export MONARCH_VERSION="${{ github.event.inputs.version }}"

        with_build_env python setup.py bdist_wheel

        # Properly retag wheel with manylinux platform tag
        retag_wheel_platform "${{ matrix.platform-tag }}"

        # Run tests
        install_python_test_dependencies
        pip install dist/*.whl
        python -c "import monarch"
  publish:
    name: Publish to PyPI
    needs: build
    runs-on: ubuntu-latest
    if: ${{ github.event_name == 'schedule' || github.event_name == 'workflow_dispatch' }}
    permissions:
      id-token: write  # Required for PyPI trusted publishing
      contents: read
    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: dist
          merge-multiple: true

      - name: Display structure of downloaded files
        run: ls -R dist/

      - name: Publish to PyPI
        uses: pypa/gh-action-pypi-publish@release/v1
        with:
          verbose: true
