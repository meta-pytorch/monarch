{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c443b989-5a71-455f-9a59-9963338634ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached job at path: .monarch/job_state.pkl\n",
      "SLURM job 7750 not found in queue\n",
      "Cached job cannot run this spec, removing cache\n",
      "Cancelled SLURM job 7750\n",
      "Applying current job\n",
      "Submitting SLURM job with 2 nodes\n",
      "SLURM job 7751 submitted. Logs will be written to: /home/mreso/monarch/examples/slurm_7751_monarch_example_1781197.out\n",
      "Saving job to cache at .monarch/job_state.pkl\n",
      "Job has started, connecting to current state\n",
      "SLURM job 7751 is running on 2 nodes: ['slurm-compute-node-074', 'slurm-compute-node-077']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m>>> Aggregated Logs (2025-11-15 00:44:19) >>>\u001b[0m\n",
      "\u001b[33m[8 similar log lines]\u001b[0m [5] self.rank=5 Initializing torch distributed\n",
      "\u001b[36m<<< Aggregated Logs (2025-11-15 00:44:22) <<<\u001b[0m\n",
      "\n",
      "\u001b[36m>>> Aggregated Logs (2025-11-15 00:44:22) >>>\u001b[0m\n",
      "\u001b[33m[8 similar log lines]\u001b[0m [0] [Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7\n",
      "\u001b[33m[8 similar log lines]\u001b[0m [0] self.rank=0 Finished initializing torch distributed\n",
      "\u001b[33m[8 similar log lines]\u001b[0m [0] self.rank=0 Running basic DDP example\n",
      "\u001b[33m[8 similar log lines]\u001b[0m [0] self.rank=0 local_rank=0\n",
      "\u001b[36m<<< Aggregated Logs (2025-11-15 00:44:25) <<<\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cancelled SLURM job 7751\n",
      "slurm.utils 2025-11-15 00:44:28 INFO Job terminated successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DDP example completed successfully!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m>>> Aggregated Logs (2025-11-15 00:44:25) >>>\u001b[0m\n",
      "\u001b[33m[8 similar log lines]\u001b[0m [4] self.rank=4 Finished running basic DDP example\n",
      "\u001b[33m[8 similar log lines]\u001b[0m [0] self.rank=0 Cleaning up torch distributed\n",
      "\u001b[36m<<< Aggregated Logs (2025-11-15 00:44:28) <<<\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (c) Meta Platforms, Inc. and affiliates. Confidential and proprietary.\n",
    "\n",
    "# @noautodeps\n",
    "# pyre-ignore-all-errors\n",
    "import logging\n",
    "import os\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from monarch.actor import Actor, current_rank, endpoint\n",
    "from monarch.utils import setup_env_for_distributed\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from slurm.utils import create_slurm_job, cleanup_job\n",
    "\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(name)s %(asctime)s %(levelname)s %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    force=True,\n",
    ")\n",
    "\n",
    "\n",
    "logger: logging.Logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class ToyModel(nn.Module):\n",
    "    \"\"\"A simple toy model for demonstration purposes.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ToyModel, self).__init__()\n",
    "        self.net1 = nn.Linear(10, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.net2 = nn.Linear(10, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net2(self.relu(self.net1(x)))\n",
    "\n",
    "\n",
    "class DDPActor(Actor):\n",
    "    \"\"\"This Actor wraps the basic functionality from Torch's DDP example.\n",
    "\n",
    "    Conveniently, all of the methods we need are already laid out for us,\n",
    "    so we can just wrap them in the usual Actor endpoint semantic with some\n",
    "    light modifications.\n",
    "\n",
    "    Adapted from: https://docs.pytorch.org/tutorials/intermediate/ddp_tutorial.html#basic-use-case\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.rank = current_rank().rank\n",
    "\n",
    "    def _rprint(self, msg):\n",
    "        \"\"\"Helper method to print with rank information.\"\"\"\n",
    "        print(f\"{self.rank=} {msg}\")\n",
    "\n",
    "    @endpoint\n",
    "    async def setup(self):\n",
    "        \"\"\"Initialize the PyTorch distributed process group.\"\"\"\n",
    "        self._rprint(\"Initializing torch distributed\")\n",
    "\n",
    "        WORLD_SIZE = int(os.environ[\"WORLD_SIZE\"])\n",
    "        # initialize the process group\n",
    "        dist.init_process_group(\"gloo\", rank=self.rank, world_size=WORLD_SIZE)\n",
    "        self._rprint(\"Finished initializing torch distributed\")\n",
    "\n",
    "    @endpoint\n",
    "    async def cleanup(self):\n",
    "        \"\"\"Clean up the PyTorch distributed process group.\"\"\"\n",
    "        self._rprint(\"Cleaning up torch distributed\")\n",
    "        dist.destroy_process_group()\n",
    "\n",
    "    @endpoint\n",
    "    async def demo_basic(self):\n",
    "        \"\"\"Run a basic DDP training example.\"\"\"\n",
    "        self._rprint(\"Running basic DDP example\")\n",
    "\n",
    "        # create model and move it to GPU with id rank\n",
    "        local_rank = int(os.environ[\"LOCAL_RANK\"])\n",
    "        self._rprint(f\"{local_rank=}\")\n",
    "        model = ToyModel().to(local_rank)\n",
    "        ddp_model = DDP(model, device_ids=[local_rank])\n",
    "\n",
    "        loss_fn = nn.MSELoss()\n",
    "        optimizer = optim.SGD(ddp_model.parameters(), lr=0.001)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = ddp_model(torch.randn(20, 10))\n",
    "        labels = torch.randn(20, 5).to(local_rank)\n",
    "        loss_fn(outputs, labels).backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"{self.rank=} Finished running basic DDP example\")\n",
    "\n",
    "\n",
    "async def main():\n",
    "    num_nodes = 2\n",
    "    gpus_per_node = 8\n",
    "    mesh_name = \"mesh0\"\n",
    "    \n",
    "    # Create SLURM job\n",
    "    slurm_job = create_slurm_job(mesh_name, num_nodes, gpus_per_node)\n",
    "\n",
    "    try:\n",
    "        # Get job state and create process mesh\n",
    "        job_state = slurm_job.state()\n",
    "        proc_mesh = job_state.mesh0.spawn_procs({\"gpus\": gpus_per_node})\n",
    "\n",
    "        # Spawn DDP actor\n",
    "        ddp_actor = proc_mesh.spawn(\"ddp_actor\", DDPActor)\n",
    "\n",
    "        # Setup distributed environment\n",
    "        await setup_env_for_distributed(proc_mesh)\n",
    "\n",
    "        # Run DDP example\n",
    "        await ddp_actor.setup.call()\n",
    "        await ddp_actor.demo_basic.call()\n",
    "        await ddp_actor.cleanup.call()\n",
    "\n",
    "        print(\"DDP example completed successfully!\")\n",
    "\n",
    "    finally:\n",
    "        await cleanup_job(slurm_job)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7fcfc7-3561-43bd-9945-278fb488e0ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (monarch)",
   "language": "python",
   "name": "monarch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
