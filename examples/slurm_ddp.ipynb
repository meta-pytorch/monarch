{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c443b989-5a71-455f-9a59-9963338634ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'compute_world_size_actor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 20\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msocket\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcloudpickle\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcompute_world_size_actor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TestActor\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmonarch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_rust_bindings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmonarch_hyperactor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malloc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AllocConstraints, AllocSpec\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# from monarch._src.actor.meta.allocator import MastAllocator, MastAllocatorConfig\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'compute_world_size_actor'"
     ]
    }
   ],
   "source": [
    "# (c) Meta Platforms, Inc. and affiliates. Confidential and proprietary.\n",
    "\n",
    "# @noautodeps\n",
    "# pyre-ignore-all-errors\n",
    "\n",
    "import argparse\n",
    "import asyncio\n",
    "import getpass\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "import math\n",
    "import os\n",
    "import socket\n",
    "\n",
    "import cloudpickle\n",
    "\n",
    "from monarch._rust_bindings.monarch_hyperactor.alloc import AllocConstraints, AllocSpec\n",
    "\n",
    "# from monarch._src.actor.meta.allocator import MastAllocator, MastAllocatorConfig\n",
    "\n",
    "from monarch.actor import ProcMesh\n",
    "from monarch.tools import commands\n",
    "from monarch.tools.components import hyperactor\n",
    "from monarch.tools.config import Config, UnnamedAppDef\n",
    "from monarch._src.actor.allocator import (\n",
    "    RemoteAllocator,\n",
    "    StaticRemoteAllocInitializer,\n",
    "    TorchXRemoteAllocInitializer,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn.functional as F\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from monarch.actor import Actor, current_rank, current_size, endpoint\n",
    "from monarch.actor import Actor, current_rank, endpoint, proc_mesh\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from example_actors.compute_world_size_actor import TestActor\n",
    "from slurm.utils import get_appdef, get_server_info, create_proc_mesh\n",
    "\n",
    "\n",
    "USER = getpass.getuser()\n",
    "HOME = pathlib.Path().home()\n",
    "CWD = os.getcwd()\n",
    "DEACTIVATE = None\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(name)s %(asctime)s %(levelname)s %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    force=True,\n",
    ")\n",
    "\n",
    "\n",
    "logger: logging.Logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "# TODO: Remove and replace with utils.setup_env_for_distributed once trunk is healthy.\n",
    "def _find_free_port() -> int:\n",
    "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "        s.bind((\"localhost\", 0))\n",
    "        addr = s.getsockname()\n",
    "        port = addr[1]\n",
    "        return port\n",
    "\n",
    "\n",
    "class _TorchDistributedInitActor(Actor):\n",
    "    def __init__(self) -> None:\n",
    "        self.rank: int = current_rank().rank\n",
    "\n",
    "    @endpoint\n",
    "    def get_host_port(self) -> tuple[str, int]:\n",
    "        return (socket.gethostname(), _find_free_port())\n",
    "\n",
    "    @endpoint\n",
    "    def setup_env(self, master_addr: str, master_port: int) -> None:\n",
    "        cr = current_rank()\n",
    "        # Assume last dimension is the local rank.\n",
    "        last_label = cr.shape.labels[-1]\n",
    "        local_world_size = cr.size(last_label)\n",
    "        world_size = len(cr)\n",
    "        global_rank = cr.rank\n",
    "        local_rank = min(world_size, global_rank % local_world_size)\n",
    "        group_rank = global_rank // local_world_size\n",
    "        group_world_size = (world_size + local_world_size - 1) // local_world_size\n",
    "        env = {\n",
    "            \"MASTER_ADDR\": master_addr,\n",
    "            \"MASTER_PORT\": str(master_port),\n",
    "            \"RANK\": str(global_rank),\n",
    "            \"LOCAL_RANK\": str(local_rank),\n",
    "            \"LOCAL_WORLD_SIZE\": str(local_world_size),\n",
    "            \"GROUP_RANK\": str(group_rank),\n",
    "            \"GROUP_WORLD_SIZE\": str(group_world_size),\n",
    "            \"ROLE_RANK\": str(global_rank),\n",
    "            \"ROLE_WORLD_SIZE\": str(world_size),\n",
    "            \"ROLE_NAME\": \"rank\",\n",
    "            \"WORLD_SIZE\": str(world_size),\n",
    "        }\n",
    "        os.environ.update(env)\n",
    "\n",
    "\n",
    "async def setup_env_for_distributed(\n",
    "    proc_mesh: ProcMesh,\n",
    "    master_addr: str | None = None,\n",
    "    master_port: int | None = None,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Sets up environment variables for pytorch distributed.\n",
    "    It selects a random proc in the proc_mesh to be the master node.\n",
    "    It sets enviornment variables like RANK, LOCAL_RANK, WORLD_SIZE, etc.\n",
    "    If master_addr and master_port are None, it will automatically select a master node and port.\n",
    "    \"\"\"\n",
    "    assert (master_addr is None) == (\n",
    "        master_port is None\n",
    "    ), \"Either both master_addr and master_port must be specified or neither must be specified.\"\n",
    "    am = await proc_mesh.spawn(\"_TorchDistributedInitActor\", _TorchDistributedInitActor)\n",
    "    if master_addr is None:\n",
    "        # We use call instead of call_one because call_one can't handle tuple return types.\n",
    "        vm = await am.flatten(\"rank\").slice(rank=0).get_host_port.call()\n",
    "        master_addr, master_port = vm.item()\n",
    "    assert master_port is not None, \"master_port should not be None here.\"\n",
    "    await am.setup_env.call(master_addr, master_port)\n",
    "\n",
    "\n",
    "class ToyModel(nn.Module):\n",
    "    \"\"\"A simple toy model for demonstration purposes.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ToyModel, self).__init__()\n",
    "        self.net1 = nn.Linear(10, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.net2 = nn.Linear(10, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net2(self.relu(self.net1(x)))\n",
    "\n",
    "\n",
    "class DDPActor(Actor):\n",
    "    \"\"\"This Actor wraps the basic functionality from Torch's DDP example.\n",
    "\n",
    "    Conveniently, all of the methods we need are already laid out for us,\n",
    "    so we can just wrap them in the usual Actor endpoint semantic with some\n",
    "    light modifications.\n",
    "\n",
    "    Adapted from: https://docs.pytorch.org/tutorials/intermediate/ddp_tutorial.html#basic-use-case\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.rank = current_rank().rank\n",
    "\n",
    "    def _rprint(self, msg):\n",
    "        \"\"\"Helper method to print with rank information.\"\"\"\n",
    "        print(f\"{self.rank=} {msg}\")\n",
    "\n",
    "    @endpoint\n",
    "    async def setup(self):\n",
    "        \"\"\"Initialize the PyTorch distributed process group.\"\"\"\n",
    "        self._rprint(\"Initializing torch distributed\")\n",
    "\n",
    "        WORLD_SIZE = int(os.environ[\"WORLD_SIZE\"])\n",
    "        # initialize the process group\n",
    "        dist.init_process_group(\"gloo\", rank=self.rank, world_size=WORLD_SIZE)\n",
    "        self._rprint(\"Finished initializing torch distributed\")\n",
    "\n",
    "    @endpoint\n",
    "    async def cleanup(self):\n",
    "        \"\"\"Clean up the PyTorch distributed process group.\"\"\"\n",
    "        self._rprint(\"Cleaning up torch distributed\")\n",
    "        dist.destroy_process_group()\n",
    "\n",
    "    @endpoint\n",
    "    async def demo_basic(self):\n",
    "        \"\"\"Run a basic DDP training example.\"\"\"\n",
    "        self._rprint(\"Running basic DDP example\")\n",
    "\n",
    "        # create model and move it to GPU with id rank\n",
    "        local_rank = int(os.environ[\"LOCAL_RANK\"])\n",
    "        self._rprint(f\"{local_rank=}\")\n",
    "        model = ToyModel().to(local_rank)\n",
    "        ddp_model = DDP(model, device_ids=[local_rank])\n",
    "\n",
    "        loss_fn = nn.MSELoss()\n",
    "        optimizer = optim.SGD(ddp_model.parameters(), lr=0.001)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = ddp_model(torch.randn(20, 10))\n",
    "        labels = torch.randn(20, 5).to(local_rank)\n",
    "        loss_fn(outputs, labels).backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"{self.rank=} Finished running basic DDP example\")\n",
    "\n",
    "\n",
    "async def main():\n",
    "    num_hosts = 2\n",
    "    appdef = await get_appdef(num_hosts)\n",
    "    server_info = await get_server_info(appdef)\n",
    "\n",
    "    try:\n",
    "        proc_mesh = await create_proc_mesh(num_hosts, appdef, server_info)\n",
    "\n",
    "        ddp_actor = await proc_mesh.spawn(\"ddp_actor\", DDPActor)\n",
    "\n",
    "        await setup_env_for_distributed(proc_mesh)\n",
    "\n",
    "        await ddp_actor.setup.call()\n",
    "        await ddp_actor.demo_basic.call()\n",
    "        await ddp_actor.cleanup.call()\n",
    "\n",
    "        print(\"DDP example completed successfully!\")\n",
    "\n",
    "    finally:\n",
    "        commands.kill(f\"slurm:///{server_info.name}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cloudpickle.register_pickle_by_value(sys.modules[TestActor.__module__])\n",
    "\n",
    "    # asyncio.run(main())\n",
    "    await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7fcfc7-3561-43bd-9945-278fb488e0ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ahmads-nightly2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
