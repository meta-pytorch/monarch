{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c443b989-5a71-455f-9a59-9963338634ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached job at path: .monarch/job_state.pkl\n",
      "Error checking job 7757 status: slurm_load_jobs error: Invalid job id specified\n",
      "\n",
      "SLURM job 7757 not found in queue\n",
      "Cached job cannot run this spec, removing cache\n",
      "Cancelled SLURM job 7757\n",
      "Applying current job\n",
      "Submitting SLURM job with 2 nodes\n",
      "SLURM job 7758 submitted. Logs will be written to: /home/mreso/monarch/examples/slurm_7758_monarch_example_1784833.out\n",
      "Saving job to cache at .monarch/job_state.pkl\n",
      "Job has started, connecting to current state\n",
      "SLURM job 7758 is running on 2 nodes: ['slurm-compute-node-090', 'slurm-compute-node-091']\n",
      "__main__ 2025-11-15 01:12:07 INFO computing world size...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m>>> Aggregated Logs (2025-11-15 01:12:06) >>>\u001b[0m\n",
      "\u001b[33m[1 similar log lines]\u001b[0m [7] Initializing process group `nccl`:\n",
      "\u001b[33m[1 similar log lines]\u001b[0m [7]   MASTER_ADDR = slurm-compute-node-090\n",
      "\u001b[33m[1 similar log lines]\u001b[0m [7]   MASTER_PORT = 29500\n",
      "\u001b[33m[1 similar log lines]\u001b[0m [7]   RANK        = 7\n",
      "\u001b[33m[1 similar log lines]\u001b[0m [7]   WORLD_SIZE  = 8\n",
      "\u001b[36m<<< Aggregated Logs (2025-11-15 01:12:09) <<<\u001b[0m\n",
      "\n",
      "\u001b[36m>>> Aggregated Logs (2025-11-15 01:12:09) >>>\u001b[0m\n",
      "\u001b[33m[7 similar log lines]\u001b[0m [4] Initializing process group `nccl`:\n",
      "\u001b[33m[7 similar log lines]\u001b[0m [4]   MASTER_ADDR = slurm-compute-node-090\n",
      "\u001b[33m[7 similar log lines]\u001b[0m [4]   MASTER_PORT = 29500\n",
      "\u001b[33m[7 similar log lines]\u001b[0m [4]   RANK        = 4\n",
      "\u001b[33m[7 similar log lines]\u001b[0m [4]   WORLD_SIZE  = 8\n",
      "\u001b[36m<<< Aggregated Logs (2025-11-15 01:12:12) <<<\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "__main__ 2025-11-15 01:12:13 INFO computed world_sizes:\n",
      "    ----------------------------------------\n",
      "    {\n",
      "  \"rank_0\": 8,\n",
      "  \"rank_1\": 8,\n",
      "  \"rank_2\": 8,\n",
      "  \"rank_3\": 8,\n",
      "  \"rank_4\": 8,\n",
      "  \"rank_5\": 8,\n",
      "  \"rank_6\": 8,\n",
      "  \"rank_7\": 8\n",
      "}\n",
      "    ----------------------------------------\n",
      "Cancelled SLURM job 7758\n",
      "slurm.utils 2025-11-15 01:12:13 INFO Job terminated successfully\n"
     ]
    }
   ],
   "source": [
    "# (c) Meta Platforms, Inc. and affiliates. Confidential and proprietary.\n",
    "\n",
    "# @noautodeps\n",
    "# pyre-ignore-all-errors\n",
    "import json\n",
    "import logging\n",
    "import socket\n",
    "import sys\n",
    "\n",
    "import cloudpickle\n",
    "from example_actors.compute_world_size_actor import ComputeWorldSizeActor\n",
    "from monarch.actor import Actor, endpoint\n",
    "from slurm.utils import create_slurm_job, cleanup_job\n",
    "\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(name)s %(asctime)s %(levelname)s %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    force=True,\n",
    ")\n",
    "\n",
    "\n",
    "logger: logging.Logger = logging.getLogger(__name__)\n",
    "\n",
    "class _HostnameActor(Actor):\n",
    "           \"\"\"Helper actor to get hostname from rank 0\"\"\"\n",
    "           @endpoint\n",
    "           def get_hostname(self) -> str:\n",
    "               return socket.gethostname()\n",
    "\n",
    "\n",
    "async def main():\n",
    "    num_nodes = 2\n",
    "    gpus_per_node = 4\n",
    "    mesh_name = \"mesh0\"\n",
    "    master_port = 29500\n",
    "\n",
    "    # Create SLURM job\n",
    "    slurm_job = create_slurm_job(mesh_name, num_nodes, gpus_per_node)\n",
    "\n",
    "    try:\n",
    "        # Get job state and create process mesh\n",
    "        job_state = slurm_job.state()\n",
    "        proc_mesh = job_state.mesh0.spawn_procs({\"gpus\": gpus_per_node})\n",
    "\n",
    "        # Get master_addr from rank 0\n",
    "        hostname_actor = proc_mesh.spawn(\"hostname_actor\", _HostnameActor)\n",
    "        hostname_values = await hostname_actor.flatten(\"rank\").slice(rank=0).get_hostname.call()\n",
    "        master_addr = hostname_values.item()\n",
    "\n",
    "        # Spawn actor\n",
    "        actor = proc_mesh.spawn(\"compute_world_size_actor\", ComputeWorldSizeActor)\n",
    "\n",
    "        logger.info(\"computing world size...\")\n",
    "        values = await actor.compute_world_size.call(\n",
    "            master_addr=master_addr,\n",
    "            master_port=master_port,\n",
    "        )\n",
    "\n",
    "        values_by_rank = {f\"rank_{p.rank}\": v for p, v in list(values.flatten(\"rank\"))}\n",
    "\n",
    "        logger.info(\n",
    "            f\"\"\"computed world_sizes:\n",
    "    {'-'*40}\n",
    "    {json.dumps(values_by_rank, indent=2)}\n",
    "    {'-'*40}\"\"\"\n",
    "        )\n",
    "    finally:\n",
    "        await cleanup_job(slurm_job)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cloudpickle.register_pickle_by_value(sys.modules[ComputeWorldSizeActor.__module__])\n",
    "    cloudpickle.register_pickle_by_value(sys.modules[_HostnameActor.__module__])\n",
    "\n",
    "    await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45417f57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (monarch)",
   "language": "python",
   "name": "monarch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
